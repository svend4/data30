# Спецификация: оценки, рекомендации и модерация

## Цель системы доверия
Система доверия нужна, чтобы пользователи могли быстро понять, насколько продукт надежен и полезен именно в их сценарии, а поставщики — получать прозрачную обратную связь о качестве и ценности. Она объединяет подтвержденные сигналы использования, оценку качества и практической эффективности, формируя понятные уровни зрелости и рекомендации.

Ключевая задача — снизить риск выбора неподходящего решения за счет разделения оценок, опоры на подтвержденное использование и прозрачного объяснения, почему продукт рекомендован в конкретном сценарии.

## Цели
- Разделить оценку качества и оценку полезности, чтобы пользователи могли отдельно фиксировать соответствие продукта стандартам и практическую ценность.
- Привязать отзыв к подтвержденному использованию, чтобы повысить достоверность.
- Ввести уровни зрелости (прототип → стабильное → рекомендовано) для прозрачности жизненного цикла.
- Описать алгоритм ранжирования по сценариям использования, а не в целом по продукту.
- Добавить модерацию и анти‑спам механизмы.
- Создать UX‑модель «почему это рекомендовано» с объяснением факторов.

## 1. Разделение оценок: качество vs полезность

### Модель данных
- `quality_rating` (1–5) — оценка качества: стабильность, соответствие стандартам, безопасность.
- `usefulness_rating` (1–5) — оценка полезности: насколько хорошо решает задачу пользователя.
- `quality_tags` — чек‑лист критериев качества (например: «стабильно», «есть документация», «прошло аудит»).
- `usefulness_tags` — чек‑лист критериев полезности (например: «экономит время», «заменяет N инструментов»).

### UX
- Две независимые шкалы в карточке отзыва.
- Обязательное текстовое обоснование для каждого типа оценки (минимум 140 символов).
- Витрина продукта показывает отдельные средние значения и их динамику.

## 2. Подтвержденное использование

### Сущности и источники подтверждения
- `verified_usage` — запись подтвержденного использования, связана с пользователем, продуктом и сценарием.
- `verification_audit` — журнал подтверждений (кто/когда подтвердил, причина, действие).

### Источники подтверждения
- Лог использования (интеграция/плагин/SDK) — факт запуска сценария.
- Подтвержденные покупки/подписки.
- Внутренние проекты/кейсы, привязанные к пользователю.

### Правила
- Отзыв можно оставить только при наличии `usage_proof` за последние 90 дней (подтвержденное использование — обязательное условие).
- Отзыв можно оставить только при наличии активного `verified_usage` (не просроченного) за последние 90 дней.
- Валидация выполняется на API/BE уровне: если подтверждения нет, запрос на создание отзыва отклоняется.
- Уровень доверия к отзыву повышается при многократном использовании (например, 5+ запусков).
- Если срок подтверждения истёк, отзыв сохраняется, но помечается как «не подтвержден свежим использованием».
- Любое ручное подтверждение/продление фиксируется в `verification_audit` с указанием актера и времени.

## 3. Уровни зрелости

### Уровни
1. **Прототип** — ограниченный функционал, низкая стабильность, публично доступен.
2. **Стабильное** — базовая функциональность закрывает ключевые сценарии, стабильность выше порога.
3. **Рекомендовано** — высокий уровень стабильности, подтвержденная полезность, поддержка/документация.

### Критерии перехода
- Прототип → Стабильное:
  - Не менее 20 подтвержденных отзывов.
  - Средняя оценка качества ≥ 3.8.
  - Отсутствие критических инцидентов за последние 30 дней.
- Стабильное → Рекомендовано:
  - Не менее 50 подтвержденных отзывов.
  - Средняя оценка качества ≥ 4.2 и полезности ≥ 4.0.
  - Наличие документации и SLA (или эквивалентной поддержки).

## 4. Алгоритм ранжирования по сценариям

### Основные принципы
- Ранжирование строится отдельно для каждого сценария (например: «автоматизация отчётов», «моделирование», «анализ данных»).
- Итоговый балл сценария определяется агрегированием оценок только пользователей, которые отметили сценарий в отзыве.

### Порядок расчета
1. Отфильтровать отзывы по сценарию и признаку `verified` за последние 12 месяцев.
2. Рассчитать средние значения `quality_score_avg` и `utility_score_avg` по отфильтрованным отзывам.
3. Применить коэффициент свежести к оценкам старше 12 месяцев (например, 0.7).
4. Рассчитать доверительный бонус на основе доли подтвержденных отзывов.
5. Учесть штраф за спам‑риск.
6. Нормализовать итоговый балл в диапазоне 1–5 для сопоставимости.

### Формула (пример)
`scenario_rank = (quality_weight * quality_rating_avg) + (usefulness_weight * usefulness_rating_avg) + trust_bonus - spam_penalty`

Где:
- `quality_weight` = 0.45
- `usefulness_weight` = 0.45
- `trust_bonus` = 0.1 * `verified_usage_ratio`
- `spam_penalty` = 0.1 * `spam_risk_score`

### Дополнительно
- Учитывать количество подтвержденных отзывов в сценарии (минимальный порог для ранжирования).
- Вводить «коэффициент свежести» — отзывы старше 12 месяцев учитываются с коэффициентом 0.7.

## 5. Таблица метрик рейтинга

| Метрика | Описание | Источник | Использование |
| --- | --- | --- | --- |
| `quality_score_avg` | Средняя оценка качества по подтвержденным отзывам | Отзывы (`verified`) | Входит в итоговый балл и уровни зрелости |
| `utility_score_avg` | Средняя оценка полезности по подтвержденным отзывам | Отзывы (`verified`) | Входит в итоговый балл и уровни зрелости |
| `verified_usage_ratio` | Доля подтвержденных отзывов от всех | Логи использования + отзывы | Доверительный бонус |
| `review_volume` | Количество подтвержденных отзывов за период | Отзывы | Порог допуска к ранжированию |
| `freshness_factor` | Коэффициент свежести отзывов | Дата отзыва | Корректировка баллов |
| `spam_risk_score` | Оценка риска спама | Анти‑спам фильтры | Штраф к рангу и приоритет модерации |
| `scenario_coverage` | Количество сценариев с подтвержденными отзывами | Отзывы + теги сценариев | Доп. критерий зрелости |
| `maturity_level` | Текущий уровень зрелости | Модуль зрелости | Витрина и фильтры |

## 6. Модерация и анти‑спам

### Анти‑спам правила
- Ограничение: не более 2 отзывов в сутки от одного пользователя.
- Автоматическое выявление повторяющихся шаблонов (N‑gram/семантическое сходство).
- Флаги риска: множественные отзывы с одного IP, аномальная частота, нет подтверждения использования.

### Модерация
- Статусы отзыва: `pending` → `approved` / `rejected`.
- Приоритетная проверка отзывов с высокими рисками.
- Логи модерации сохраняются (кто, когда, причина).

## 7. UX‑модель «почему это рекомендовано»

### Компоненты объяснения
- Топ‑3 причин (например: «Высокая полезность для сценария X», «Стабильное качество», «Высокий доверительный рейтинг»).
- Вклад факторов в итоговый балл (мини‑гистограмма или процентное распределение).
- Количество подтвержденных пользователей и сценариев.

### UX‑описание
На карточке продукта и в списке рекомендаций показывается блок «Почему это рекомендовано», который объясняет, какие факторы повлияли на позицию. Пользователь видит краткое резюме (2–3 причины), отдельные значения качества/полезности, долю подтвержденных отзывов и сценарий, в котором продукт рекомендован.

### Пример текста
> Рекомендовано для сценария «Анализ данных» благодаря высокой полезности (4.6), стабильному качеству (4.4) и 82% подтвержденных отзывов.

## Метрики мониторинга
- Доля подтвержденных отзывов.
- Средняя оценка качества и полезности по сценариям.
- Количество спам‑отзывов, отклоненных модерацией.
- Доля продуктов в статусе «рекомендовано».

## 7. Поиск и рекомендации: цель, типы запросов, фильтры

### Цель поиска и рекомендаций
Поиск помогает пользователю быстро находить функции, модули и приложения, релевантные его задаче, а рекомендации помогают сократить выбор, предлагая наиболее подходящие варианты на основе контекста, поведения и похожих сценариев. В результате пользователь получает релевантные решения без необходимости разбираться в полном каталоге.

Рекомендации дополняют поиск, предлагая альтернативы и лучшие практики в рамках выбранного сценария: если пользователь ищет инструмент для автоматизации отчётов, система не только ранжирует результаты, но и подсказывает близкие сценарии и проверенные макросы.

### Типы пользовательских запросов
- **По цели**: «автоматизировать отчёты», «собрать витрину данных», «построить ML‑модель».
- **По функции**: «экспорт в CSV», «парсинг PDF», «автопланировщик задач».
- **По платформе**: «под Linux», «для Google Sheets», «встраивается в Slack».
- **По ограничениям**: «без оплаты», «офлайн», «SOC2/ISO», «без внешних API».

### Фильтры
- **Стоимость**: бесплатное / freemium / платное / enterprise.
- **Зрелость**: прототип / стабильное / рекомендовано.
- **Совместимость**: ОС, среда исполнения, зависимости, интеграции.
- **Категория**: аналитика, интеграции, автоматизация, ML/AI, безопасность.
- **Рейтинг**: средний `quality_score`, средний `utility_score`, доверительный рейтинг.

## 8. Логика релевантности и ранжирование

### Приоритеты релевантности
1. **Функции** — точное соответствие требуемым возможностям (features).
2. **Сценарии** — насколько продукт закрывает конкретный use‑case пользователя.
3. **Приложения** — соответствие платформе, зрелости и ограничениям.

### Ранжирование
- Основной скоринг строится по совпадению функций и сценариев, затем корректируется по ограничениям и зрелости.
- При равных очках применяется сортировка по рейтингу и подтверждённым отзывам.

### Таблица: тип запроса → результаты → критерии сортировки

| Тип запроса | Результаты | Критерии сортировки |
| --- | --- | --- |
| По цели | Сценарии и наборы продуктов под задачу | Совпадение сценария → полезность → зрелость |
| По функции | Продукты с нужными возможностями | Совпадение функций → качество → совместимость |
| По платформе | Продукты, интеграции и плагины | Совместимость → качество → полезность |
| По ограничениям | Только соответствующие требованиям продукты | Соответствие ограничениям → зрелость → рейтинг |

## 9. Рекомендации: типы и правила объяснимости

### Типы рекомендаций
- **Похожие сценарии**: предложения соседних use‑case для расширения задачи (например, после «автоматизация отчётов» → «мониторинг KPI»).
- **Альтернативы**: продукты с теми же функциями, но другой ценой/платформой/зрелостью.
- **Лучшие макросы**: макросы с максимальной полезностью и подтверждённым использованием.

### Правила объяснимости
- Показывать 2–3 причины: совпадение функций, соответствие сценариям, подтверждённые отзывы.
- Указывать ключевые ограничения, которые продукт покрывает (например, «работает офлайн»).
- Для макросов — показывать эффект («экономит 2 часа/неделю») и источник подтверждения.

## 10. UX‑прототип (текстовое описание)

**Экран поиска**
- Верхняя строка: поле поиска + чипы фильтров (стоимость, зрелость, совместимость, категория, рейтинг).
- Слева: блок «Сценарии» (подсказки по цели).
- Справа: результаты списка с быстрыми метками функций и зрелости.

**Карточка результата**
- Заголовок, тип (функция/модуль/приложение), рейтинг качества/полезности.
- Блок «Почему в выдаче»: 2–3 причины (совпадение функции, сценарий, ограничения).
- Кнопка «Похожие сценарии» и «Альтернативы».

**Блок рекомендаций**
- «Похожие сценарии» (горизонтальный список).
- «Альтернативы» (табличный список с сравнениями).
- «Лучшие макросы» (топ‑3 с показателем эффекта и подтверждением).
## 7. API и формы ввода отзывов

### Создание/редактирование отзыва
Обязательные поля:
- `quality_rating` (1–5)
- `usefulness_rating` (1–5)

Опциональные поля:
- `quality_comment`, `usefulness_comment`
- `quality_tags[]`, `usefulness_tags[]`
- `usage_proof_id`

### Валидация
- обе оценки обязательны для новых и обновляемых отзывов;
- диапазон значений 1–5;
- текстовые комментарии рекомендуются при оценках ниже 3 (UI подсказка).

## 8. Агрегаты и UI‑отображение

### Агрегаты
- хранить раздельные средние (`quality_rating_avg`, `usefulness_rating_avg`);
- хранить раздельные распределения (например, `{"1": 2, "2": 4, "3": 10, "4": 25, "5": 9}`);
- пересчитывать агрегаты отдельно для подтвержденных отзывов и для всех отзывов.

### UI
- два независимых индикатора: «Качество» и «Полезность»;
- показывать средние значения и распределения по обеим шкалам.

## 9. Миграция существующих данных

### Стратегия
Варианты миграции:
1. **Split‑default**: текущее поле рейтинга копируется в `quality_rating` и `usefulness_rating`, а в `legacy_rating_source` фиксируется `split_default`.
2. **Legacy‑only**: сохранять исходное значение в `legacy_rating`, а новые поля оставлять `NULL`, с пометкой `legacy_only`.

### Рекомендованный путь
- применить `split_default` для большинства записей;
- оставить возможность ручного переопределения, меняя `legacy_rating_source` на `manual_override`.

## 10. Аналитика и отчеты

### Обновления метрик
- разделить метрики качества и полезности во всех витринах;
- пересчитать тренды отдельно для `quality_rating` и `usefulness_rating`;
- обновить дашборды, чтобы отображать две оси и сравнение.

### Историческая совместимость
- для периодов до миграции использовать `legacy_rating` в отдельных срезах или явно помечать в отчетах как `legacy`.
## Таблица метрик

| Метрика | Описание | Источник данных |
| --- | --- | --- |
| Доля подтвержденных отзывов | Процент отзывов с актуальным `usage_proof` за 90 дней | Логи использования, подписки/покупки, проектные кейсы |
| Средняя оценка качества по сценарию | Среднее значение `quality_score` среди отзывов, отметивших сценарий | Отзывы пользователей |
| Средняя оценка полезности по сценарию | Среднее значение `utility_score` среди отзывов, отметивших сценарий | Отзывы пользователей |
| Коэффициент свежести | Доля отзывов моложе 12 месяцев, влияющая на ранжирование | Отзывы пользователей |
| Verified usage ratio | Доля подтвержденных отзывов среди всех отзывов по сценарию | Отзывы пользователей, логи использования |
| Spam risk score | Суммарный риск спама по шаблонам/частоте/совпадениям | Модерация, анти‑спам сигналы |
| Доля продуктов «рекомендовано» | Процент продуктов, достигших уровня Recommended | Реестр продуктов, витрина |
## 7. Поиск и релевантность

### 7.1 Типы запросов
Классификация запроса используется для выбора фильтров, ранжирования и объяснимости.

- **По цели (job‑to‑be‑done)**: «нужен инструмент для…», «как автоматизировать…».
  - Определяет ведущий сценарий и веса полезности.
- **По функции**: «OCR», «извлечение сущностей», «генерация отчётов».
  - Матчится с каталогом функций и тэгами.
- **По платформе**: «Windows», «Mac», «Android», «Chrome‑расширение», «API».
  - Сужает доступные продукты/интеграции.
- **По ограничениям**: «он‑премис», «без внешнего интернета», «GDPR», «до 100$».
  - Применяет жесткие фильтры совместимости/стоимости.

### 7.2 Фильтры
- **Стоимость**: бесплатное / freemium / подписка / одноразовая покупка / enterprise.
  - Дополнительно: диапазон бюджета (min‑max) и TCO‑метка.
- **Зрелость**: прототип / стабильное / рекомендовано.
- **Совместимость**: ОС, браузеры, облака, требуемые зависимости, форматы.
- **Рейтинг**:
  - Качество (quality_score_avg).
  - Полезность (utility_score_avg).
  - Доверие (verified_usage_ratio).

### 7.3 Логика релевантности
Ранжирование следует цепочке **функции → сценарии → приложения**:
1. **Функции**: распознаются по ключевым словам запроса и маппятся на `function_tags`.
2. **Сценарии**: каждую функцию связываем с набором сценариев (матрица `function → scenario`).
3. **Приложения/продукты**: ранжируются в рамках сценария с учетом оценок, зрелости и ограничений.

Базовый скор релевантности:
`relevance = function_match * 0.4 + scenario_fit * 0.35 + product_quality * 0.15 + product_utility * 0.1`

### 7.4 Правила рекомендаций и объяснимость
- **Рекомендации строятся только по сценариям**, где есть подтвержденные отзывы выше порога.
- **Объяснимость**: пользователь видит 2–3 причины выбора (совпадение функции, релевантность сценария, качество/полезность).
- **Ограничения имеют приоритет**: если продукт не проходит ограничения (on‑prem, GDPR, бюджет), он исключается до ранжирования.
- **Диверсификация**: в топ‑N включать минимум 1 продукт из «стабильных» и 1 из «рекомендованных», если доступны.
- **Новые продукты**: допускаются в выдачу при совпадении по функции и наличии минимального количества проверенных запусков.

### 7.5 Таблица: Тип запроса → Результаты → Сортировка

| Тип запроса | Результаты | Сортировка |
| --- | --- | --- |
| По цели | Сценарии + приложения, закрывающие job‑to‑be‑done | relevance → utility_score_avg → verified_usage_ratio |
| По функции | Приложения с совпадением `function_tags` | function_match → quality_score_avg → maturity |
| По платформе | Приложения, совместимые с указанной платформой | relevance → compatibility_score → quality_score_avg |
| По ограничениям | Приложения, проходящие фильтры ограничений | compliance_score → maturity → verified_usage_ratio |

### 7.6 UX‑описание поиска
Пользователь вводит запрос в строку поиска. Система определяет тип запроса и предлагает подсказки:
- быстрые фильтры (платформа, стоимость, зрелость),
- уточнение сценария (например, «автоматизация отчётов»),
- список функций, извлеченных из запроса.

Выдача отображается карточками продукта с тремя блоками:
1. **Совпадение запроса** (какая функция/сценарий найден).
2. **Качество и полезность** (две оценки + доля подтвержденных отзывов).
3. **Совместимость и ограничения** (платформы, требования, бюджет).

Каждая карточка содержит кнопку «Почему рекомендовано?», раскрывающую объяснимость: ведущий сценарий, вклад факторов в ранжирование и статус зрелости.
